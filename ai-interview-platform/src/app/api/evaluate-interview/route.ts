import { NextRequest, NextResponse } from 'next/server'
import { createClient } from '@/utils/supabase/server'
import { GoogleGenAI } from '@google/genai'

interface TranscriptEntry {
    role: 'ai' | 'user'
    text: string
}

export async function POST(req: NextRequest) {
    const supabase = await createClient()
    const { data: { user }, error: authError } = await supabase.auth.getUser()
    if (authError || !user) {
        return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    const { interviewId, transcript, jobRole, numQuestions, companyName, jdText, durationSeconds } = await req.json()

    if (!interviewId || !transcript || !Array.isArray(transcript)) {
        return NextResponse.json({ error: 'Missing interviewId or transcript' }, { status: 400 })
    }

    const apiKey = process.env.GOOGLE_GEMINI_API_KEY
    if (!apiKey) {
        return NextResponse.json({ error: 'API key not configured' }, { status: 500 })
    }

    const ai = new GoogleGenAI({ apiKey })

    // Format transcript for evaluation
    const formattedTranscript = (transcript as TranscriptEntry[])
        .map(entry => `${entry.role === 'ai' ? 'Interviewer' : 'Candidate'}: ${entry.text}`)
        .join('\n\n')

    const evaluationPrompt = `You are a strict, objective technical interview evaluator. You must analyze the transcript below and evaluate the candidate's performance. The interview was conversational, so questions and answers may span multiple back-and-forth exchanges.

**CRITICAL RULES:**
1. **NO HALLUCINATION:** You must ONLY evaluate topics that were ACTUALLY DISCUSSED in the transcript. Do not invent, assume, or pull questions from a template.
2. Group the conversation into "Core Topics" or "Main Questions" that were assessed.
3. If the candidate failed to answer, dodged the question, or said "I don't know" to a topic, score THAT topic as 0.0.
4. **EXACT COUNT:** You must identify and evaluate EXACTLY the first ${numQuestions || 'Unknown'} primary Technical/Core topics the interviewer asked about. If the interviewer asked more than ${numQuestions || 'Unknown'} topics, ignore the extra ones for scoring. If the interviewer asked fewer, only evaluate what was asked. The \`totalQuestions\` field must reflect the true number of core topics you evaluated.
5. **SPEECH-TO-TEXT TOLERANCE:** The candidate's text is generated by an imperfect Speech-to-Text API. It will contain phonetic mistakes, missing punctuation, and grammatical errors (e.g., "oh notation" instead of "Big O notation", "Cadence already" instead of "Kadane's algorithm"). DO NOT penalize the candidate for these errors. You MUST infer the intended technical meaning from the context before evaluating their knowledge.

**Interview Context metadata:**
- Role: ${jobRole || 'Not specified'}
- Company: ${companyName || 'Not specified'}
- Expected/Requested Question Count: ${numQuestions || 'Unknown'}
- Job Description Context: ${jdText || 'None provided'}

**Transcript:**
${formattedTranscript}

**Your Task:**
Identify the main topics or questions discussed. For each actual core topic the interviewer tested (up to a maximum of ${numQuestions || 'Unknown'}), provide:
1. "question": A summary of the core question or topic discussed (e.g., "Explain the CSS Box Model").
2. "score": A score from 0.0 to 1.0 evaluating the candidate's overall answer(s) on this topic.
3. "feedback": Brief feedback on the candidate's specific responses regarding this topic.

Then provide an overall summary with specific improvement suggestions based ONLY on the evidence in the transcript. Include feedback on any casual conversation that happened after the core questions in this summary area.

**IMPORTANT: Respond ONLY with valid JSON in this exact format:**
{
    "questions": [
        {
            "question": "Summary of topic or question actually discussed",
            "score": 0.75,
            "feedback": "Brief feedback on the answer quality based on the conversation"
        }
    ],
    "totalScore": 7.5,
    "totalQuestions": 1, // The number of distinct core topics evaluated
    "summaryFeedback": "A detailed 3-5 paragraph summary covering: 1) Overall performance, 2) Key strengths, 3) Specific weaknesses needing improvement, 4) Actionable next steps"
}`

    try {
        const models = ['gemini-2.5-flash', 'gemini-2.0-flash'];
        let response: any = null;

        for (const model of models) {
            try {
                response = await ai.models.generateContent({
                    model,
                    contents: evaluationPrompt,
                });
                break; // Success — stop trying
            } catch (modelErr: any) {
                const isRateLimit = modelErr?.message?.includes('429') || modelErr?.message?.includes('RESOURCE_EXHAUSTED');
                if (isRateLimit) {
                    console.warn(`Rate limited on ${model}, trying next model after 15s...`);
                    await new Promise(r => setTimeout(r, 15000));
                    continue;
                }
                throw modelErr;
            }
        }

        if (!response) {
            // All models rate-limited — return 429 to client so it shows the right message
            return NextResponse.json(
                { error: 'Rate limit exceeded. Please wait about 30 seconds and retry.' },
                { status: 429 }
            );
        }

        let resultText = response.text || ''

        // Clean up potential markdown code blocks
        resultText = resultText.replace(/```json\s*/g, '').replace(/```\s*/g, '').trim()

        // Extract the JSON object between first { and last }
        const jsonStart = resultText.indexOf('{')
        const jsonEnd = resultText.lastIndexOf('}')
        if (jsonStart === -1 || jsonEnd === -1) {
            throw new Error('No JSON object found in response')
        }
        resultText = resultText.substring(jsonStart, jsonEnd + 1)

        // Escape control characters ONLY inside JSON string values
        // Match quoted strings and escape control chars within them
        resultText = resultText.replace(/"(?:[^"\\]|\\.)*"/g, (match: string) => {
            return match.replace(/[\x00-\x1F\x7F]/g, (ch: string) => {
                if (ch === '\n') return '\\n';
                if (ch === '\r') return '\\r';
                if (ch === '\t') return '\\t';
                return '';
            });
        });

        const evaluation = JSON.parse(resultText)

        // Save per-question responses to DB
        if (evaluation.questions && Array.isArray(evaluation.questions)) {
            const responses = evaluation.questions.map((q: any) => ({
                interview_id: interviewId,
                question_text: q.question,
                user_answer: '',  // We don't have the exact user audio text
                ai_feedback: q.feedback,
                rating: q.score,
            }))

            const { error: respError } = await supabase
                .from('responses')
                .insert(responses)

            if (respError) {
                console.error('Error saving responses:', respError)
            }
        }

        // Update interview with final score, actual question count, and summary
        const { error: updateError } = await supabase
            .from('interviews')
            .update({
                final_score: evaluation.totalScore,
                num_questions: evaluation.totalQuestions, // Overwrite target with actual evaluated count
                summary_feedback: evaluation.summaryFeedback,
                ...(durationSeconds ? { duration_seconds: durationSeconds } : {}),
            })
            .eq('id', interviewId)

        if (updateError) {
            console.error('Error updating interview:', updateError)
        }

        return NextResponse.json({
            success: true,
            totalScore: evaluation.totalScore,
            totalQuestions: evaluation.totalQuestions,
            summaryFeedback: evaluation.summaryFeedback,
            questions: evaluation.questions,
        })
    } catch (err: any) {
        console.error('Evaluation error:', err)
        return NextResponse.json({ error: 'Failed to evaluate interview', details: err.message }, { status: 500 })
    }
}
